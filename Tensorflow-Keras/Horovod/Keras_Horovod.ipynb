{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras and Horovod\n",
    "\n",
    "In the markdown cells, I'll be showing the code changed needed\n",
    "\n",
    "In the end, the horovod loop needs to be in a file, I'll add that file to the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.optimizers.legacy as optimizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horovod Imports\n",
    "\n",
    "```python\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import horovod\n",
    "import horovod.tensorflow.keras as hvd\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32),tf.cast(mnist_labels, tf.int64)))\n",
    "dataset = dataset.repeat().shuffle(10000).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "mnist_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, [3, 3], activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, [3, 3], activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Param\n",
    "\n",
    "lr = 0.001\n",
    "opt = optimizers.Adam(lr)\n",
    "mnist_model.compile(loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "                    optimizer=opt,\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horvod changes\n",
    "\n",
    "```py\n",
    "# Horovod: adjust learning rate based on number of GPUs.\n",
    "scaled_lr = 0.001 * hvd.size()\n",
    "opt = optimizers.Adam(scaled_lr)\n",
    "\n",
    "# Horovod: add Horovod DistributedOptimizer.\n",
    "opt = hvd.DistributedOptimizer(\n",
    "    opt, backward_passes_per_step=1, average_aggregated_gradients=True)\n",
    "\n",
    "# Horovod: Specify `experimental_run_tf_function=False` to ensure TensorFlow\n",
    "# uses hvd.DistributedOptimizer() to compute gradients.\n",
    "mnist_model.compile(loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "                    optimizer=opt,\n",
    "                    metrics=['accuracy'],\n",
    "                    experimental_run_tf_function=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks and train\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "callbacks.append(tf.keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n",
    "\n",
    "mnist_model.fit(dataset, steps_per_epoch=500 , callbacks=callbacks, epochs=24)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horovod way\n",
    "\n",
    "```py\n",
    "callbacks = [\n",
    "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "    # This is necessary to ensure consistent initialization of all workers when\n",
    "    # training is started with random weights or restored from a checkpoint.\n",
    "    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "\n",
    "    # Horovod: average metrics among workers at the end of every epoch.\n",
    "    #\n",
    "    # Note: This callback must be in the list before the ReduceLROnPlateau,\n",
    "    # TensorBoard or other metrics-based callbacks.\n",
    "    hvd.callbacks.MetricAverageCallback(),\n",
    "    \n",
    "    # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final\n",
    "    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during\n",
    "    # the first three epochs. See https://arxiv.org/abs/1706.02677 for details.\n",
    "    hvd.callbacks.LearningRateWarmupCallback(initial_lr=scaled_lr, warmup_epochs=3, verbose=1),\n",
    "]\n",
    "\n",
    "# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\n",
    "if hvd.rank() == 0:\n",
    "    callbacks.append(tf.keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n",
    "\n",
    "# Horovod: write logs on worker 0.\n",
    "verbose = 1 if hvd.rank() == 0 else 0\n",
    "\n",
    "# Train the model.\n",
    "# Horovod: adjust number of steps based on number of GPUs.\n",
    "mnist_model.fit(dataset, steps_per_epoch=500 // hvd.size(), callbacks=callbacks, epochs=24, verbose=verbose)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horovod Notes\n",
    "\n",
    "Recommended to pin the process to GPU with\n",
    "\n",
    "```py\n",
    "# Horovod: pin GPU to be used to process local rank (one GPU per process)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n",
    "```\n",
    "\n",
    "You have to have the training in a script, and the code must begin with `hvd.init()`\n",
    "\n",
    "Some callbacks are not supported should be only run on rank 0, like log writing, checkpoint saving etc..\n",
    "\n",
    "Finally, entire codeblock should be in a main function, and called at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f401cf1dbab24df559ae8789ef7eacae25a0fecff741eceb08aecb7249ab0875"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
